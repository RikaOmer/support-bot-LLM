import os
import shutil
from langchain_core.documents import Document 
from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# --- ×”×’×“×¨×•×ª ---
# ×¢×“×›×Ÿ ××ª ×”× ×ª×™×‘ ×œ×¤×™ ×”××‘× ×” ×©×œ×š
DATA_PATH = os.path.join(os.path.dirname(__file__), "markdown")
DB_PATH = "chroma_db"
# ××•×“×œ Embedding ××©×•×¤×¨ - ×§×œ ×™×•×ª×¨ ×•××™×›×•×ª×™ ×™×•×ª×¨ ×œ×¢×‘×¨×™×ª
# ××¤×©×¨×•×™×•×ª: "intfloat/multilingual-e5-small" (×§×œ, ~130MB), "paraphrase-multilingual-mpnet-base-v2" (××™×›×•×ª ×˜×•×‘×” ×™×•×ª×¨, ~420MB)
HF_MODEL_NAME = "intfloat/multilingual-e5-small"  # ×§×œ ×××•×“, ××¦×•×™×Ÿ ×œ×¢×‘×¨×™×ª

def build_database():
    # 1. × ×™×§×•×™ DB ×™×©×Ÿ
    if os.path.exists(DB_PATH):
        print("ğŸ—‘ï¸ ××•×—×§ ×“××˜×”-×‘×™×™×¡ ×™×©×Ÿ...")
        shutil.rmtree(DB_PATH)

    # 2. ×§×¨×™××ª ×§×‘×¦×™×
    if not os.path.exists(DATA_PATH):
        print("âŒ ×©×’×™××”: ×ª×™×§×™×™×ª ×”×“××˜×” ×œ× ×§×™×™××ª.")
        print(f"   × ×ª×™×‘ × ×“×¨×©: {DATA_PATH}")
        return

    print("ğŸ“– ×§×•×¨× ×§×‘×¦×™ Markdown ×•××‘×¦×¢ ×—×œ×•×§×” ×—×›××”...")
    
    # ×”×’×“×¨×ª ×”×—×œ×•×§×” ×œ×¤×™ ×›×•×ª×¨×•×ª - ×–×” ×”×§×¡×!
    # ×–×” ×©×•××¨ ××ª ×”×›×•×ª×¨×ª ×›×—×œ×§ ××”××™×“×¢ ×©×œ ×›×œ ××§×˜×¢
    headers_to_split_on = [
        ("#", "Header 1"),
        ("##", "Header 2"),
        ("###", "Header 3"),
    ]
    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)

    all_header_splits = []
    files = [f for f in os.listdir(DATA_PATH) if f.endswith('.md')]
    
    for filename in files:
        file_path = os.path.join(DATA_PATH, filename)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # ×—×œ×•×§×” ×¨××©×•× ×™×ª ×œ×¤×™ ×›×•×ª×¨×•×ª
                md_header_splits = markdown_splitter.split_text(content)
                
                # ×”×•×¡×¤×ª ×©× ×”×§×•×‘×¥ ×œ××˜×-×“××˜×”
                for doc in md_header_splits:
                    doc.metadata["source"] = filename
                    # ×©×™×œ×•×‘ ×”×›×•×ª×¨×•×ª ×œ×ª×•×š ×”×˜×§×¡×˜ ×¢×¦××• ×›×“×™ ×©×”××•×“×œ ×™×¨××” ××•×ª×Ÿ ×‘×‘×™×¨×•×¨
                    header_context = " > ".join([v for k, v in doc.metadata.items() if k.startswith("Header")])
                    if header_context:
                        doc.page_content = f"× ×•×©×: {header_context}\n\n{doc.page_content}"
                
                all_header_splits.extend(md_header_splits)
                
        except Exception as e:
            print(f"   âŒ × ×›×©×œ ×‘×˜×¢×™× ×ª {filename}: {e}")

    print(f"âœ… × ×•×¦×¨×• {len(all_header_splits)} ××§×˜×¢×™× ××‘×•×¡×¡×™ ×›×•×ª×¨×•×ª.")

    # 3. ×—×œ×•×§×” ××©× ×™×ª (×× ×™×© ××§×˜×¢×™× ××¨×•×›×™× ××“×™ ×’× ××—×¨×™ ×”×—×œ×•×§×” ×œ×›×•×ª×¨×•×ª)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=600,
        chunk_overlap=150
    )
    final_chunks = text_splitter.split_documents(all_header_splits)
    print(f"âœ‚ï¸ ×—×œ×•×§×” ×¡×•×¤×™×ª ×œ-{len(final_chunks)} ××§×˜×¢×™×.")

    # 4. ×™×¦×™×¨×ª ×”-Vector DB
    print("ğŸš€ ×‘×•× ×” ××™× ×“×§×¡...")
    print(f"ğŸ”¤ ××©×ª××© ×‘××•×“×œ Embedding: {HF_MODEL_NAME}")
    embedding_function = HuggingFaceEmbeddings(model_name=HF_MODEL_NAME)
    
    Chroma.from_documents(
        documents=final_chunks,
        embedding=embedding_function,
        persist_directory=DB_PATH
    )
    
    print("âœ¨ ×”×“××˜×” ×‘×™×™×¡ ×”×—×“×© ××•×›×Ÿ!")

if __name__ == "__main__":
    build_database()
